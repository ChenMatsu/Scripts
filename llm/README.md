# LLM Embedded with Terminals

There are several ways to embed llm into your terminals.

1. Create a bash or python script with curl cmd calling api from openapi with key, and add alias the script as a cmd in the llm embedded terminal.
2. Run a docker container with pretrained model locally, and create a script which calls the local llm model.

